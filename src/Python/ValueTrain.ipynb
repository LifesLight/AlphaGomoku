{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.0 using mps device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from Utilities import Utilities as Utils\n",
    "from NeuralNet import ResidualNetwork as ResNet\n",
    "from NeuralNet import PolicyNetwork as PolicyHead\n",
    "from NeuralNet import ValueNetwork as ValueHead\n",
    "\n",
    "import os\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f'Torch: {torch.__version__} using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(ConstructedModel, Path):\n",
    "    ConstructedModel.load_state_dict(torch.load(Path, map_location=torch.device('cpu')))\n",
    "    ConstructedModel.eval()\n",
    "    ConstructedModel.to(device)\n",
    "\n",
    "def loadDataset(Path, Shape):\n",
    "    return torch.from_numpy(np.fromfile(Path, dtype=bool).astype(np.float32).reshape((Shape)))\n",
    "\n",
    "def toDataloader(X, Y, BatchSize=128, Shuffle=False):\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    return DataLoader(dataset, batch_size=BatchSize, shuffle=Shuffle)\n",
    "\n",
    "def trainValue(dataloader, resNet, valNet, val_loss, optimizer, epoch, logcount=5, wandb_log=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    loginterval = len(dataloader) // logcount\n",
    "    averageValLoss = 0.0\n",
    "\n",
    "    resNet.train()\n",
    "    valNet.train()\n",
    "    for batch, (X, yPol) in enumerate(dataloader):\n",
    "        X, yPol = X.to(device), yPol.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        resNetOut = resNet(X)\n",
    "        valPred = valNet(resNetOut)\n",
    "        valLoss = val_loss(valPred, yPol)\n",
    "\n",
    "        averageValLoss += valLoss.detach().item()\n",
    "        # Backpropagation\n",
    "        valLoss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if (batch % loginterval == 0) and (batch > 0):\n",
    "            logValLoss = averageValLoss / loginterval\n",
    "            averageValLoss = 0\n",
    "            current = batch * len(X)\n",
    "            print(f\"Val Loss: {logValLoss:>8f} [{current:>5d}/{size:>5d}]\")\n",
    "            if wandb_log:\n",
    "                wandb.log({\"epoch\": epoch, \"trainValLoss\": logValLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = 128\n",
    "Layers = 13\n",
    "HistoryDepth = 8\n",
    "BatchSize = 128\n",
    "LogCount = 5\n",
    "datasetPath = \"../../Datasets/HumanExamples/GeneratedDatasets/HD8,AUG,TS0.8,RULESETS(1)\"\n",
    "\n",
    "X = loadDataset(f'{datasetPath}/XTrain.bin', (-1, HistoryDepth + 1, 15, 15))\n",
    "Y = loadDataset(f'{datasetPath}/YTrainVal.bin', (-1, 1))\n",
    "dataloader = toDataloader(X, Y, BatchSize=BatchSize, Shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet = ResNet(Filters, Layers, HistoryDepth + 1)\n",
    "loadModel(resNet, \"../../Models/Human/ResNet/ResNet.pt\")\n",
    "\n",
    "for param in resNet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "valHead = ValueHead(Filters).to(device)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(valHead.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Val Loss: 0.132071 [76928/3847720]\n",
      "Val Loss: 0.119759 [153856/3847720]\n",
      "Val Loss: 0.120535 [230784/3847720]\n",
      "Val Loss: 0.117745 [307712/3847720]\n",
      "Val Loss: 0.118940 [384640/3847720]\n",
      "Val Loss: 0.118785 [461568/3847720]\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "valHeadCheckpoints = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    trainValue(dataloader, resNet, valHead, loss, optimizer, epoch, logcount=50, wandb_log=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
